{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/arccyan/tresnet-wrap.1839d738-4e70-49e6-a12f-f76a9114d7ab.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250606/auto/storage/goog4_request&X-Goog-Date=20250606T070800Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=14422473c8954e155af94242b391c9fc14ebd37d6bf3b533d572cfc30478ca9c588f5d14b9f33dc9aeb2db58faa746f33df7fc7c4edb92f2bd3c0478fe98d2d6071b65d9a0eb0173f12a6c44adb991cad536df67a631c190ffa9aaa485b67c31ef739e1361005ca815d5abfaabadbfb0f48e23d4bcc45fb5d7687295b150b84375bd2ecc49fc5e118a4bfbf91b2fd867249ec429ce590a26dd49c177b23eeb788b65d5a5048f16ab7344385f39b6145a86afb0237010930b65748fd7943552e596b8903017fbd290422539d89fdf7d72f4830e83ded815d0ec4e0ede41e400e9ae1baa45763e5840671d2e47b7931e0090bc9e631bdd2bec1453a4e006b3fe85","timestamp":1749193690205}],"machine_shape":"hm"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11918208,"sourceType":"datasetVersion","datasetId":7492523},{"sourceId":12072954,"sourceType":"datasetVersion","datasetId":7599597}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"10a5ccfa65d341bb88a3fa7b57302b10":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_311428f487334daaa27bdfbdec114d48"],"layout":"IPY_MODEL_c9332fa777624c23bb13fd32a49e2c06"}},"830fe8d1dee742ae8530f400999a445e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4175b33bf1a24facade0a1ebd796885a","placeholder":"​","style":"IPY_MODEL_bf771d4326af44fca13b0044d38ff001","value":"<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"}},"5dccaed9b4d543e3b816d21e55c181a6":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Username:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_fbfeabc9ebac45f0b72c3b061636cf51","placeholder":"​","style":"IPY_MODEL_901dd51271844ab79cbc43447b75a459","value":"arccyan"}},"ca2aa276e4c9438b89297344dbf50fe0":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_defb1d3bebda4518b79c49836d9e5bbe","placeholder":"​","style":"IPY_MODEL_a89d72e621054bfe891795908fb0f4db","value":""}},"b43af0cfb2f84212ad1f460fdf852218":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_0bd9bb50af1a4dfc9bfb9bdd1e5ab1cd","style":"IPY_MODEL_9d6bfdc58ab04175a4046f17acb90819","tooltip":""}},"034bd1eed54c40158f21fbca0e9dc84a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9d677dad6ab4cad9eaa54f06e34fc0e","placeholder":"​","style":"IPY_MODEL_64260a22f84f464e8818cda1f2c4674d","value":"\n<b>Thank You</b></center>"}},"c9332fa777624c23bb13fd32a49e2c06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"4175b33bf1a24facade0a1ebd796885a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf771d4326af44fca13b0044d38ff001":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbfeabc9ebac45f0b72c3b061636cf51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901dd51271844ab79cbc43447b75a459":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"defb1d3bebda4518b79c49836d9e5bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a89d72e621054bfe891795908fb0f4db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bd9bb50af1a4dfc9bfb9bdd1e5ab1cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6bfdc58ab04175a4046f17acb90819":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"a9d677dad6ab4cad9eaa54f06e34fc0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64260a22f84f464e8818cda1f2c4674d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef61280505c34b26ba5f59f1532d0437":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b46ccb5f1cd40a780459cffbcad5e63","placeholder":"​","style":"IPY_MODEL_8547a5ad35824753bda359cb025b8e19","value":"Connecting..."}},"1b46ccb5f1cd40a780459cffbcad5e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8547a5ad35824753bda359cb025b8e19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"311428f487334daaa27bdfbdec114d48":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_309666d8aa9741acb64a1a63c936acc9","placeholder":"​","style":"IPY_MODEL_0fcfd69fc5ba48bd9d24a5e7543e7939","value":"Kaggle credentials successfully validated."}},"309666d8aa9741acb64a1a63c936acc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fcfd69fc5ba48bd9d24a5e7543e7939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"source":[],"metadata":{"id":"2OAO9v9jEW2O","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["10a5ccfa65d341bb88a3fa7b57302b10","830fe8d1dee742ae8530f400999a445e","5dccaed9b4d543e3b816d21e55c181a6","ca2aa276e4c9438b89297344dbf50fe0","b43af0cfb2f84212ad1f460fdf852218","034bd1eed54c40158f21fbca0e9dc84a","c9332fa777624c23bb13fd32a49e2c06","4175b33bf1a24facade0a1ebd796885a","bf771d4326af44fca13b0044d38ff001","fbfeabc9ebac45f0b72c3b061636cf51","901dd51271844ab79cbc43447b75a459","defb1d3bebda4518b79c49836d9e5bbe","a89d72e621054bfe891795908fb0f4db","0bd9bb50af1a4dfc9bfb9bdd1e5ab1cd","9d6bfdc58ab04175a4046f17acb90819","a9d677dad6ab4cad9eaa54f06e34fc0e","64260a22f84f464e8818cda1f2c4674d","ef61280505c34b26ba5f59f1532d0437","1b46ccb5f1cd40a780459cffbcad5e63","8547a5ad35824753bda359cb025b8e19","311428f487334daaa27bdfbdec114d48","309666d8aa9741acb64a1a63c936acc9","0fcfd69fc5ba48bd9d24a5e7543e7939"]},"executionInfo":{"status":"ok","timestamp":1749201028926,"user_tz":-540,"elapsed":375,"user":{"displayName":"박진영","userId":"15299328254354703813"}},"outputId":"6929c0f0-c9eb-402c-fd2e-503cc527c03d"},"cell_type":"code","outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a5ccfa65d341bb88a3fa7b57302b10"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Kaggle credentials set.\n","Kaggle credentials successfully validated.\n"]}],"execution_count":null},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yv_yOvDCVaKC","executionInfo":{"status":"ok","timestamp":1749284122216,"user_tz":-540,"elapsed":2395,"user":{"displayName":"박진영","userId":"15299328254354703813"}},"outputId":"93a0f113-48ae-435e-8530-499bdf0d56f8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"source":["# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","arccyan_tresnet_stanford_cars_pretrained_path = '/content/drive/MyDrive/Obsidian/Dacon/Hecto_AI_Challenge/Pretrained'\n","arccyan_upscaled_car_datasets_path = '/content/drive/MyDrive/Obsidian/Dacon/Hecto_AI_Challenge'\n","\n","print('Data source import complete.')\n"],"metadata":{"id":"hHALW9zREW2O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201043069,"user_tz":-540,"elapsed":1402,"user":{"displayName":"박진영","userId":"15299328254354703813"}},"outputId":"6362784f-4b22-4eae-beef-5ec600f49bf1"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["Data source import complete.\n"]}],"execution_count":null},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"L3oV47WeCKcn"}},{"cell_type":"code","source":["import os\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch import nn, optim\n","\n","from sklearn.metrics import log_loss\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-06-05T17:26:35.102656Z","iopub.execute_input":"2025-06-05T17:26:35.102861Z","iopub.status.idle":"2025-06-05T17:27:12.638288Z","shell.execute_reply.started":"2025-06-05T17:26:35.102839Z","shell.execute_reply":"2025-06-05T17:27:12.632403Z"},"executionInfo":{"elapsed":7245,"status":"ok","timestamp":1749201050312,"user":{"displayName":"박진영","userId":"15299328254354703813"},"user_tz":-540},"id":"5VRIs0HCCKco","outputId":"dd95d285-e97a-4f38-ba6b-930cf4966efb","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"execution_count":null},{"cell_type":"code","source":["!pip install wandb\n","import wandb"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:45:53.500032Z","iopub.execute_input":"2025-06-05T15:45:53.500425Z","iopub.status.idle":"2025-06-05T15:46:02.314491Z","shell.execute_reply.started":"2025-06-05T15:45:53.500367Z","shell.execute_reply":"2025-06-05T15:46:02.313658Z"},"id":"SavOoqD5EW2Q","outputId":"a335ea60-69a0-45be-c176-e325b4cb3c13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201054886,"user_tz":-540,"elapsed":4555,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"]}],"execution_count":null},{"cell_type":"code","source":["!pip install inplace-abn\n","!pip install early_stopping_pytorch\n","from early_stopping_pytorch import EarlyStopping"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:02.316674Z","iopub.execute_input":"2025-06-05T15:46:02.317134Z","iopub.status.idle":"2025-06-05T15:46:18.653938Z","shell.execute_reply.started":"2025-06-05T15:46:02.317108Z","shell.execute_reply":"2025-06-05T15:46:18.65273Z"},"trusted":true,"id":"otrAU65lEW2Q","outputId":"d8204006-a6f6-49a5-f236-9a7c80906e07","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201065458,"user_tz":-540,"elapsed":10569,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: inplace-abn in /usr/local/lib/python3.11/dist-packages (1.1.0)\n","Requirement already satisfied: early_stopping_pytorch in /usr/local/lib/python3.11/dist-packages (1.0.10)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from early_stopping_pytorch) (2.0.2)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from early_stopping_pytorch) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->early_stopping_pytorch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->early_stopping_pytorch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->early_stopping_pytorch) (3.0.2)\n"]}],"execution_count":null},{"cell_type":"code","source":["!git clone https://github.com/Alibaba-MIIL/TResNet\n","%cd TResNet"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:18.655472Z","iopub.execute_input":"2025-06-05T15:46:18.655884Z","iopub.status.idle":"2025-06-05T15:46:19.556553Z","shell.execute_reply.started":"2025-06-05T15:46:18.655835Z","shell.execute_reply":"2025-06-05T15:46:19.55542Z"},"trusted":true,"id":"PdQq66tWEW2R","outputId":"ed30cc8a-0c4d-4fbd-b3ee-57526aaeb4dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201065595,"user_tz":-540,"elapsed":134,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'TResNet' already exists and is not an empty directory.\n","/content/TResNet\n"]}],"execution_count":null},{"cell_type":"markdown","source":["# Hyperparameter Setting"],"metadata":{"id":"6hXgRhYKCKcp"}},{"cell_type":"code","source":["CFG = {\n","    'IMG_SIZE': 421,\n","    'CROP_SIZE': 368,\n","    'BATCH_SIZE': 32,\n","    'EPOCHS': 30,\n","    'LEARNING_RATE': 0.002,\n","    'SEED' : 42\n","}"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:19.557823Z","iopub.execute_input":"2025-06-05T15:46:19.558134Z","iopub.status.idle":"2025-06-05T15:46:19.563148Z","shell.execute_reply.started":"2025-06-05T15:46:19.558104Z","shell.execute_reply":"2025-06-05T15:46:19.561943Z"},"id":"xvRCnuRqCKcp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["!wandb login 1128bf290760f1cd846378e87ab026431fee90c3"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:19.564273Z","iopub.execute_input":"2025-06-05T15:46:19.564691Z","iopub.status.idle":"2025-06-05T15:46:24.467379Z","shell.execute_reply.started":"2025-06-05T15:46:19.564662Z","shell.execute_reply":"2025-06-05T15:46:24.466139Z"},"trusted":true,"id":"Dco4JZO8EW2S","outputId":"7c15d295-a10c-49d7-89c9-398a562624d3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201072818,"user_tz":-540,"elapsed":7209,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"execution_count":null},{"cell_type":"code","source":["# Initialize wandb\n","wandb.init(\n","    entity='Dacon_Car',\n","    project=\"car-classification\",  # your project name\n","    name='TResNet_random_crop_SAM_CELoss',\n","    config=CFG  # this will log your hyperparameters\n",")"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:24.46873Z","iopub.execute_input":"2025-06-05T15:46:24.469236Z","iopub.status.idle":"2025-06-05T15:46:37.017841Z","shell.execute_reply.started":"2025-06-05T15:46:24.469202Z","shell.execute_reply":"2025-06-05T15:46:37.017091Z"},"trusted":true,"id":"46lfdahaEW2S","outputId":"4f11c7d7-8d85-4d8b-89bd-964972cd4cbc","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1749201076551,"user_tz":-540,"elapsed":3734,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msingiri129\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/TResNet/wandb/run-20250606_091113-c7ukvciv</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/Dacon_Car/car-classification/runs/c7ukvciv' target=\"_blank\">TResNet_random_crop_SAM_CELoss</a></strong> to <a href='https://wandb.ai/Dacon_Car/car-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/Dacon_Car/car-classification' target=\"_blank\">https://wandb.ai/Dacon_Car/car-classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/Dacon_Car/car-classification/runs/c7ukvciv' target=\"_blank\">https://wandb.ai/Dacon_Car/car-classification/runs/c7ukvciv</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/Dacon_Car/car-classification/runs/c7ukvciv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x796d12b7ca50>"]},"metadata":{},"execution_count":9}],"execution_count":null},{"cell_type":"markdown","source":["# Fixed RandomSeed"],"metadata":{"id":"ullOr-KjCKcp"}},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(CFG['SEED']) # Seed 고정"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:37.018849Z","iopub.execute_input":"2025-06-05T15:46:37.019212Z","iopub.status.idle":"2025-06-05T15:46:37.032902Z","shell.execute_reply.started":"2025-06-05T15:46:37.019182Z","shell.execute_reply":"2025-06-05T15:46:37.031941Z"},"id":"Uwop2i4qCKcp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# CustomDataset"],"metadata":{"id":"AUwzuA7jCKcq"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np # NumPy 임포트 추가\n","from torch.utils.data import Dataset\n","# albumentations와 ToTensorV2 임포트는 Dataset 클래스 외부에서 이루어져야 합니다.\n","# import albumentations as A\n","# from albumentations.pytorch import ToTensorV2\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, is_test=False):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","        self.samples = []\n","\n","        if is_test:\n","            # 테스트셋: 라벨 없이 이미지 경로만 저장\n","            for fname in sorted(os.listdir(root_dir)):\n","                if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # 이미지 확장자 추가\n","                    img_path = os.path.join(root_dir, fname)\n","                    self.samples.append((img_path,))\n","        else:\n","            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n","            self.classes = sorted(os.listdir(root_dir))\n","            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","            for cls_name in self.classes:\n","                cls_folder = os.path.join(root_dir, cls_name)\n","                # 폴더가 아닌 파일이 있을 수 있으므로 isdir 체크 추가\n","                if not os.path.isdir(cls_folder):\n","                    continue\n","                for fname in os.listdir(cls_folder):\n","                    if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # 이미지 확장자 추가\n","                        img_path = os.path.join(cls_folder, fname)\n","                        label = self.class_to_idx[cls_name]\n","                        self.samples.append((img_path, label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        if self.is_test:\n","            img_path = self.samples[idx][0]\n","            image = Image.open(img_path).convert('RGB')\n","            # PIL 이미지를 NumPy 배열로 변환\n","            image = np.array(image)\n","\n","            if self.transform:\n","                # Albumentations는 딕셔너리를 반환하며 'image' 키에 변환된 이미지가 있습니다.\n","                transformed_data = self.transform(image=image)\n","                image = transformed_data['image'] # PyTorch 텐서 (C, H, W)\n","\n","            return image\n","        else:\n","            img_path, label = self.samples[idx]\n","            image = Image.open(img_path).convert('RGB')\n","            # PIL 이미지를 NumPy 배열로 변환\n","            image = np.array(image)\n","\n","            if self.transform:\n","                # Albumentations는 딕셔너리를 반환하며 'image' 키에 변환된 이미지가 있습니다.\n","                transformed_data = self.transform(image=image)\n","                image = transformed_data['image'] # PyTorch 텐서 (C, H, W)\n","\n","            return image, label"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:37.035732Z","iopub.execute_input":"2025-06-05T15:46:37.036Z","iopub.status.idle":"2025-06-05T15:46:37.050115Z","shell.execute_reply.started":"2025-06-05T15:46:37.035969Z","shell.execute_reply":"2025-06-05T15:46:37.049049Z"},"id":"EOA2BdsbCKcq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Data Load"],"metadata":{"id":"6bmib4EdCKcq"}},{"cell_type":"code","source":["train_root = f'{arccyan_upscaled_car_datasets_path}/upscaled/train'\n","test_root = f'{arccyan_upscaled_car_datasets_path}upscaled/test'"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:37.050986Z","iopub.execute_input":"2025-06-05T15:46:37.051331Z","iopub.status.idle":"2025-06-05T15:46:37.069912Z","shell.execute_reply.started":"2025-06-05T15:46:37.05131Z","shell.execute_reply":"2025-06-05T15:46:37.068754Z"},"id":"GLNBNSyDCKcq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2 # PyTorch 텐서로 변환하기 위함\n","import numpy as np # Albumentations는 NumPy 배열을 입력으로 받습니다.\n","from PIL import Image # 이미지 로딩을 위한 라이브러리\n","\n","# Albumentations의 train_transform\n","train_transform = A.Compose([\n","\n","\n","    # ResizeIfPadNeeded는 가로세로 비율을 유지하면서 이미지의 긴 변 또는 짧은 변을 리사이즈한 다음,\n","    # 지정된 크기에 맞춰 패딩을 추가합니다.\n","    # pad_height, pad_width는 최종 출력 크기를 의미합니다.\n","    # 만약 원본 비율을 유지하면서 패딩으로 채우는 것이 목적이라면 아래와 같이 LongestMaxSize와 PadIfNeeded를 사용합니다.\n","    A.LongestMaxSize(max_size=CFG['IMG_SIZE']*1.5, interpolation=Image.BILINEAR),\n","    A.PadIfNeeded(min_height=CFG['IMG_SIZE']*1.5, min_width=CFG['IMG_SIZE']*1.5,\n","                border_mode=0, fill=(0,0,0)), # border_mode=0 (CONSTANT), value는 패딩 색상\n","\n","    A.RandomCrop(\n","        height=int(CFG['CROP_SIZE']),   # 예: 294 (368*0.8), 더 작게 하고 싶으면 0.6~0.8 추천\n","        width=int(CFG['CROP_SIZE']),    # 전체 면적의 60~100%에서 랜덤 크롭\n","        p=0.5\n","    ),\n","    A.Resize(height = int(CFG['CROP_SIZE']), width = int(CFG['CROP_SIZE']), interpolation=Image.BILINEAR),)\n","    A.HorizontalFlip(p=0.5),\n","    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=0.5),\n","    A.A.Affine(\n","    # 일반적으로 학습 시에는 Resize 후 Normalize를 많이 사용합니다.\n","    # torchvision의 Normalize와 동일한 mean/std 값을 사용합니다.\n","    A.Normalize(mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0), # 이미지 픽셀 값의 최댓값 (일반적으로 255)\n","\n","    # Albumentations의 ToTensorV2는 이미지를 PyTorch 텐서로 변환하고 채널 순서를 (H, W, C) -> (C, H, W)로 변경합니다.\n","    # torchvision의 ToTensor()와 유사하게 동작합니다.\n","    ToTensorV2()\n","])\n","\n","# Albumentations의 val_transform (train_transform과 동일하게 구성)\n","val_transform = A.Compose([\n","    # 검증 시에도 동일하게 Resize 및 Normalize를 적용합니다.\n","    A.LongestMaxSize(max_size=CFG['CROP_SIZE'], interpolation=Image.BILINEAR),\n","    A.PadIfNeeded(min_height=CFG['CROP_SIZE'], min_width=CFG['CROP_SIZE'],\n","                border_mode=0, fill=(0,0,0)), # border_mode=0 (CONSTANT), value는 패딩 색상\n","    # A.CenterCrop(\n","    #     height=int(CFG['CROP_SIZE']),   # 예: 294 (368*0.8), 더 작게 하고 싶으면 0.6~0.8 추천\n","    #     width=int(CFG['CROP_SIZE']),    # 전체 면적의 60~100%에서 랜덤 크롭\n","    #     p=1.0\n","    # ),\n","    A.Normalize(mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","                max_pixel_value=255.0),\n","    ToTensorV2()\n","])"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:42.279931Z","iopub.execute_input":"2025-06-05T15:46:42.280386Z","iopub.status.idle":"2025-06-05T15:46:43.351435Z","shell.execute_reply.started":"2025-06-05T15:46:42.280337Z","shell.execute_reply":"2025-06-05T15:46:43.350651Z"},"trusted":true,"id":"qleosJXMEW2U"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 전체 데이터셋 로드\n","full_dataset = CustomImageDataset(train_root, transform=None)\n","print(f\"총 이미지 수: {len(full_dataset)}\")\n","\n","targets = [label for _, label in full_dataset.samples]\n","class_names = full_dataset.classes\n","\n","# Stratified Split\n","train_idx, val_idx = train_test_split(\n","    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",")\n","\n","# Subset + transform 각각 적용\n","train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n","val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n","print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n","\n","\n","# DataLoader 정의\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:43.352428Z","iopub.execute_input":"2025-06-05T15:46:43.35274Z","iopub.status.idle":"2025-06-05T15:46:51.69797Z","shell.execute_reply.started":"2025-06-05T15:46:43.352711Z","shell.execute_reply":"2025-06-05T15:46:51.69704Z"},"id":"ip3a8tsEEW2U","outputId":"00451298-b1a5-412e-fd4f-a5fa32390562","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749201078323,"user_tz":-540,"elapsed":325,"user":{"displayName":"박진영","userId":"15299328254354703813"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["총 이미지 수: 33137\n","train 이미지 수: 26509, valid 이미지 수: 6628\n"]}],"execution_count":null},{"cell_type":"markdown","source":["# Model Define"],"metadata":{"id":"fM0RBKa5CKcr"}},{"cell_type":"code","source":["from src.models.tresnet_v2.tresnet_v2 import TResnetL_V2 as TResnetL368\n","\n","\n","class TResNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(TResNet, self).__init__()\n","        model_params = {'num_classes' : 196}\n","        self.backbone = TResnetL368(model_params)\n","\n","        weights_path = \"/kaggle/input/tresnet-stanford-cars-pretrained/stanford_cars_tresnet-l-v2_96_27.pth\"\n","        pretrained_weights = torch.load(weights_path)\n","\n","        self.backbone.load_state_dict(pretrained_weights['model'])  # TResnetL368 모델 불러오기\n","        self.feature_dim = self.backbone.num_features\n","        self.backbone.head = nn.Identity()  # feature extractor로만 사용\n","        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.head(x)\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:51.698824Z","iopub.execute_input":"2025-06-05T15:46:51.699102Z","iopub.status.idle":"2025-06-05T15:46:51.839347Z","shell.execute_reply.started":"2025-06-05T15:46:51.699082Z","shell.execute_reply":"2025-06-05T15:46:51.838009Z"},"trusted":true,"id":"JboihZ-YEW2U"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["class TResNet_Student(nn.Module):\n","    def __init__(self, num_classes):\n","        super(TResNet_Student, self).__init__()\n","        model_params = {'num_classes' : 196}\n","        self.backbone = TResnetL368(model_params)\n","        net_layers = list(self.backbone.children())\n","        classifier = net_layers[1:3]\n","        net_layers = net_layers[0]\n","        net_layers = list(net_layers.children())\n","\n","        # Network_Wrapper 생성\n","        self.model = Student_Wrapper(net_layers, classifier).to(device)\n","        weights_path = '/content/sample_data/Stanford_Cars_TResNet-L_Student_Weight.pth'\n","        pretrained_weights = torch.load(weights_path)\n","        # self.model.load_state_dict(pretrained_weights['model'])\n","        self.model.load_state_dict(pretrained_weights)\n","        self.feature_dim = self.model.classifier_initial[0].fc.in_features\n","        self.model.classifier_initial = nn.Identity()  # feature extractor로만 사용\n","        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = self.head(x)\n","        return x"],"metadata":{"id":"WlcSi4ZYXAM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn.modules.batchnorm import _BatchNorm\n","\n","def cosine_anneal_schedule(t, nb_epoch, lr):\n","    cos_inner = np.pi * (t % (nb_epoch))\n","    cos_inner /= (nb_epoch)\n","    cos_out = np.cos(cos_inner) + 1\n","\n","    return float(lr / 2 * cos_out)\n","\n","class BasicConv(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n","        super(BasicConv, self).__init__()\n","        self.out_channels = out_planes\n","        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n","                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n","                                 momentum=0.01, affine=True) if bn else None\n","        self.relu = nn.ReLU() if relu else None\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.bn is not None:\n","            x = self.bn(x)\n","        if self.relu is not None:\n","            x = self.relu(x)\n","        return x\n","\n","class Features(nn.Module):\n","    def __init__(self, net_layers_FeatureHead):\n","        super(Features, self).__init__()\n","        self.net_layer_0 = nn.Sequential(net_layers_FeatureHead[0])\n","        self.net_layer_1 = nn.Sequential(*net_layers_FeatureHead[1])\n","        self.net_layer_2 = nn.Sequential(*net_layers_FeatureHead[2])\n","        self.net_layer_3 = nn.Sequential(*net_layers_FeatureHead[3])\n","        self.net_layer_4 = nn.Sequential(*net_layers_FeatureHead[4])\n","        self.net_layer_5 = nn.Sequential(*net_layers_FeatureHead[5])\n","\n","    def forward(self, x):\n","        x = self.net_layer_0(x)\n","        x = self.net_layer_1(x)\n","        x = self.net_layer_2(x)\n","        x1 = self.net_layer_3(x)\n","        x2 = self.net_layer_4(x1)\n","        x3 = self.net_layer_5(x2)\n","\n","        return x1, x2, x3\n","\n","\n","class Network_Wrapper(nn.Module):\n","    def __init__(self, net_layers, num_classes, classifier):\n","        super().__init__()\n","        self.Features = Features(net_layers)\n","        self.classifier_pool = nn.Sequential(classifier[0])\n","\n","        # classifier_initial을 num_classes에 맞게 수정\n","        self.classifier_initial = nn.Linear(2048, num_classes)  # 기존 196을 num_classes로 변경\n","\n","        self.sigmoid = nn.Sigmoid()\n","        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","\n","        self.max_pool1 = nn.MaxPool2d(kernel_size=46, stride=1)\n","        self.max_pool2 = nn.MaxPool2d(kernel_size=23, stride=1)\n","        self.max_pool3 = nn.MaxPool2d(kernel_size=12, stride=1)\n","\n","        self.conv_block1 = nn.Sequential(\n","            BasicConv(512, 512, kernel_size=1, stride=1, padding=0, relu=True),\n","            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n","        )\n","        self.classifier1 = nn.Sequential(\n","            nn.BatchNorm1d(1024),\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ELU(inplace=True),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","        self.conv_block2 = nn.Sequential(\n","            BasicConv(1024, 512, kernel_size=1, stride=1, padding=0, relu=True),\n","            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n","        )\n","        self.classifier2 = nn.Sequential(\n","            nn.BatchNorm1d(1024),\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ELU(inplace=True),\n","            nn.Linear(512, num_classes),\n","        )\n","\n","        self.conv_block3 = nn.Sequential(\n","            BasicConv(2048, 512, kernel_size=1, stride=1, padding=0, relu=True),\n","            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n","        )\n","        self.classifier3 = nn.Sequential(\n","            nn.BatchNorm1d(1024),\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ELU(inplace=True),\n","            nn.Linear(512, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        _, _, x3 = self.Features(x) # , x2, x3\n","        # map1 = x1.clone()\n","        # map2 = x2.clone()\n","        # map3 = x3.clone()\n","\n","        classifiers = self.classifier_pool(x3).view(x3.size(0), -1)\n","        classifiers = self.classifier_initial(classifiers)  # 이제 num_classes 출력\n","\n","        # x1_ = self.conv_block1(x1)\n","        # x1_ = self.max_pool1(x1_)\n","        # x1_f = x1_.view(x1_.size(0), -1)\n","\n","        # x1_c = self.classifier1(x1_f)\n","\n","        # x2_ = self.conv_block2(x2)\n","        # x2_ = self.max_pool2(x2_)\n","        # x2_f = x2_.view(x2_.size(0), -1)\n","        # x2_c = self.classifier2(x2_f)\n","\n","        # x3_ = self.conv_block3(x3)\n","        # x3_ = self.max_pool3(x3_)\n","        # x3_f = x3_.view(x3_.size(0), -1)\n","        # x3_c = self.classifier3(x3_f)\n","\n","        return classifiers #x1_c , x2_c, x3_c , map1, map2, map3\n","\n","\n","class Anti_Noise_Decoder(nn.Module):\n","    def __init__(self, scale, in_channel):\n","        super(Anti_Noise_Decoder, self).__init__()\n","        self.Sigmoid = nn.Sigmoid()\n","\n","        in_channel = in_channel // (scale * scale)\n","\n","        self.skip = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n","            nn.Conv2d(64, 3, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","\n","        )\n","\n","        self.process = nn.Sequential(\n","            nn.PixelShuffle(scale),\n","            nn.Conv2d(in_channel, 256, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(32, 64, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(16, 3, 3, 1, 1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        )\n","\n","    def forward(self, x, map):\n","        x_ = self.process(map)\n","        if not (x.size() == x_.size()):\n","            x_ = F.interpolate(x, (x.size(2),x.size(3)), mode='bilinear')\n","        return self.skip(x) + x_\n","\n","\n","def img_add_noise(x, transformation_seq):\n","    x = x.permute(0, 2, 3, 1)\n","    x = x.cpu().numpy()\n","    x = transformation_seq(images=x)\n","    x = torch.from_numpy(x.astype(np.float32))\n","    x = x.permute(0, 3, 1, 2)\n","    return x\n","\n","def smooth_crossentropy(pred, gold, smoothing=0.1):\n","    n_class = pred.size(1)\n","\n","    one_hot = torch.full_like(pred, fill_value=smoothing / (n_class - 1))\n","    one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - smoothing)\n","    log_prob = F.log_softmax(pred, dim=1)\n","\n","    return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1)\n","\n","def CELoss(x, y):\n","    return smooth_crossentropy(x, y, smoothing=0.1)\n","\n","class CharbonnierLoss(nn.Module):\n","    \"\"\"Charbonnier Loss (L1)\"\"\"\n","\n","    def __init__(self, eps=1e-3):\n","        super(CharbonnierLoss, self).__init__()\n","        self.eps = eps\n","\n","    def forward(self, x, y):\n","        diff = x - y\n","        # loss = torch.sum(torch.sqrt(diff * diff + self.eps))\n","        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps*self.eps)))\n","        return loss\n","\n","\n","\n","\n","def disable_running_stats(model):\n","    def _disable(module):\n","        if isinstance(module, _BatchNorm):\n","            module.backup_momentum = module.momentum\n","            module.momentum = 0\n","\n","    model.apply(_disable)\n","\n","def enable_running_stats(model):\n","    def _enable(module):\n","        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n","            module.momentum = module.backup_momentum\n","\n","    model.apply(_enable)\n","\n","\n","class Student_Wrapper(nn.Module):\n","    def __init__(self, net_layers, classifier):\n","        super(Student_Wrapper, self).__init__()\n","        self.net_layer_0 = nn.Sequential(net_layers[0])\n","        self.net_layer_1 = nn.Sequential(*net_layers[1])\n","        self.net_layer_2 = nn.Sequential(*net_layers[2])\n","        self.net_layer_3 = nn.Sequential(*net_layers[3])\n","        self.net_layer_4 = nn.Sequential(*net_layers[4])\n","        self.net_layer_5 = nn.Sequential(*net_layers[5])\n","\n","        self.classifier_pool = nn.Sequential(classifier[0])\n","        self.classifier_initial = nn.Sequential(classifier[1])\n","\n","    def forward(self, x):\n","        x = self.net_layer_0(x)\n","        x = self.net_layer_1(x)\n","        x = self.net_layer_2(x)\n","        x1 = self.net_layer_3(x)\n","        x2 = self.net_layer_4(x1)\n","        x3 = self.net_layer_5(x2)\n","\n","\n","        classifiers = self.classifier_pool(x3).view(x3.size(0), -1)\n","        out = self.classifier_initial(classifiers)\n","\n","        return out #, x1, x2, x3"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:47:17.853745Z","iopub.execute_input":"2025-06-05T15:47:17.854086Z","iopub.status.idle":"2025-06-05T15:47:17.886348Z","shell.execute_reply.started":"2025-06-05T15:47:17.854059Z","shell.execute_reply":"2025-06-05T15:47:17.885486Z"},"id":"_oyo3V3iEW2U"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# SAM\n","class SAM(torch.optim.Optimizer):\n","    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n","        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n","\n","        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n","        super(SAM, self).__init__(params, defaults)\n","\n","        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n","        self.param_groups = self.base_optimizer.param_groups\n","        self.defaults.update(self.base_optimizer.defaults)\n","\n","    @torch.no_grad()\n","    def first_step(self, zero_grad=False):\n","        grad_norm = self._grad_norm()\n","        for group in self.param_groups:\n","            scale = group[\"rho\"] / (grad_norm + 1e-12)\n","\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                self.state[p][\"old_p\"] = p.data.clone()\n","                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n","                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n","\n","        if zero_grad: self.zero_grad()\n","\n","    @torch.no_grad()\n","    def second_step(self, zero_grad=False):\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n","\n","        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n","\n","        if zero_grad: self.zero_grad()\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n","        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n","\n","        self.first_step(zero_grad=True)\n","        closure()\n","        self.second_step()\n","\n","    def _grad_norm(self):\n","        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n","        norm = torch.norm(\n","                    torch.stack([\n","                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n","                        for group in self.param_groups for p in group[\"params\"]\n","                        if p.grad is not None\n","                    ]),\n","                    p=2\n","               )\n","        return norm\n","\n","    def load_state_dict(self, state_dict):\n","        super().load_state_dict(state_dict)\n","        self.base_optimizer.param_groups = self.param_groups"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:47:23.299185Z","iopub.execute_input":"2025-06-05T15:47:23.299511Z","iopub.status.idle":"2025-06-05T15:47:23.312275Z","shell.execute_reply.started":"2025-06-05T15:47:23.299489Z","shell.execute_reply":"2025-06-05T15:47:23.311253Z"},"id":"JnfZ1OM5EW2V"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","\n","early_stopping = EarlyStopping(\n","    patience=CFG.get('PATIENCE', 3),  # 10 에포크 기다림\n","    verbose=True,                      # 진행상황 출력\n","    delta=CFG.get('delta', 0.001),                       # 최소 개선 임계값\n","    path='best_model.pth'              # 모델 저장 경로\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:47:27.563361Z","iopub.execute_input":"2025-06-05T15:47:27.56448Z","iopub.status.idle":"2025-06-05T15:47:27.589722Z","shell.execute_reply.started":"2025-06-05T15:47:27.564432Z","shell.execute_reply":"2025-06-05T15:47:27.588608Z"},"id":"3tyRimJzEW2V"},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"id":"T-uk-4_BO6cP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train/ Validation"],"metadata":{"id":"NGlK2nPYCKcr"}},{"cell_type":"code","source":["model = TResNet_Student(num_classes=len(class_names)).to(device)\n","best_logloss = float('inf')\n","\n","# 손실 함수\n","criterion = CELoss\n","\n","# PMAL\n","# model_params = {'num_classes' : 196}\n","# model = TResnetL368(model_params)\n","##weights_path = f\"{arccyan_tresnet_stanford_cars_pretrained_path}/stanford_cars_tresnet-l-v2_96_27.pth\" # '/content/Stanford_Cars_TResNet-L_Teacher_Weight.pth' #\n","#pretrained_weights = torch.load(weights_path)\n","#model.load_state_dict(pretrained_weights['model'])\n","\n","#net_layers = list(model.children())\n","#classifier = net_layers[1:3]\n","#net_layers = net_layers[0]\n","#net_layers = list(net_layers.children())\n","\n","# Network_Wrapper 생성\n","#model = Student_Wrapper(net_layers, classifier).to(device)\n","\n","# 옵티마이저\n","#optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n","\n","base_optimizer = torch.optim.SGD\n","\n","optimizer = SAM(\n","    model.parameters(),\n","    base_optimizer,\n","    lr=CFG['LEARNING_RATE'],\n","    adaptive=False,\n","    momentum=0.9,\n","    weight_decay=5e-4\n",")\n","\n","\n","# 학습 및 검증 루프\n","for epoch in range(CFG['EPOCHS']):\n","    # Train\n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.param_groups[0]['lr'] = cosine_anneal_schedule(epoch, CFG['EPOCHS'], CFG['LEARNING_RATE'])\n","        def closure():\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels).mean()\n","            loss.backward()\n","            return loss\n","\n","        loss = closure()\n","        optimizer.step(closure)\n","        # optimizer.zero_grad()\n","        # outputs = model(images)  # logits\n","        # loss = criterion(outputs, labels).mean()\n","        # loss.backward()\n","        # optimizer.step()\n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_probs = []\n","    all_labels = []\n","    all_pred_labels = []\n","    class_correct = [0 for _ in range(len(class_names))]\n","    class_total = [0 for _ in range(len(class_names))]\n","\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels).mean()\n","            val_loss += loss.item()\n","\n","            # Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","            for label, pred in zip(labels.cpu().numpy(), preds.cpu().numpy()):\n","                class_total[label] += 1\n","                if label == pred:\n","                    class_correct[label] += 1\n","\n","\n","            # LogLoss\n","            probs = F.softmax(outputs, dim=1)\n","            all_probs.extend(probs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","            all_pred_labels.extend(preds.cpu().numpy())\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_accuracy = 100 * correct / total\n","    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n","\n","\n","    # wandb\n","    wandb.log({\n","        \"train_loss\": avg_train_loss,\n","        \"val_loss\": avg_val_loss,\n","        \"val_accuracy\": val_accuracy,\n","        \"val_logloss\": val_logloss\n","    })\n","\n","    # 결과 출력\n","    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n","\n","    # Best model 저장\n","    if val_logloss < best_logloss:\n","        class_acc = [c / t if t > 0 else 0 for c, t in zip(class_correct, class_total)]\n","        df_class_acc = pd.DataFrame({\n","            'Class Name': class_names,\n","            'Correct': class_correct,\n","            'Total': class_total,\n","            'Accuracy': class_acc\n","        }).sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n","\n","        df_pred_detail = pd.DataFrame({\n","            'TrueLabel': all_labels,\n","            'PredLabel': all_pred_labels,\n","            'TrueClass': [class_names[i] for i in all_labels],\n","            'PredClass': [class_names[i] for i in all_pred_labels]\n","        })\n","        df_pred_detail.to_csv(f'val_pred_detail_epoch_{epoch+1}.csv', index=False, encoding='utf-8-sig')\n","        # epoch 번호를 파일명에 포함하여 저장\n","        df_class_acc.to_csv(f'class_acc_epoch_{epoch+1}.csv', index=False, encoding='utf-8-sig')\n","        best_logloss = val_logloss\n","        torch.save(model.state_dict(), f'best_model.pth')\n","        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")\n","\n","    early_stopping(val_logloss, model)\n","    if early_stopping.early_stop:\n","        print(f\"🛑 Early stopping triggered at epoch {epoch+1}\")\n","        break"],"metadata":{"execution":{"iopub.status.busy":"2025-06-05T15:46:51.847361Z","iopub.status.idle":"2025-06-05T15:46:51.847759Z","shell.execute_reply.started":"2025-06-05T15:46:51.847601Z","shell.execute_reply":"2025-06-05T15:46:51.847618Z"},"id":"DwNWkTC3CKcr","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"703925f1-d834-4a78-f6f2-4d120963451e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[Epoch 1/30] Training: 100%|██████████| 829/829 [52:09<00:00,  3.78s/it]\n","[Epoch 1/30] Validation: 100%|██████████| 208/208 [04:18<00:00,  1.24s/it]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 4.0678 || Valid Loss : 2.4317 | Valid Accuracy : 37.3265%\n","📦 Best model saved at epoch 1 (logloss: 2.8896)\n","Validation loss decreased (inf --> 2.889629).  Saving model ...\n"]},{"output_type":"stream","name":"stderr","text":["[Epoch 2/30] Training: 100%|██████████| 829/829 [52:05<00:00,  3.77s/it]\n","[Epoch 2/30] Validation: 100%|██████████| 208/208 [04:27<00:00,  1.29s/it]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 1.7243 || Valid Loss : 1.1350 | Valid Accuracy : 70.7604%\n","📦 Best model saved at epoch 2 (logloss: 1.2566)\n","Validation loss decreased (2.889629 --> 1.256646).  Saving model ...\n"]},{"output_type":"stream","name":"stderr","text":["[Epoch 3/30] Training:  42%|████▏     | 347/829 [21:57<30:23,  3.78s/it]"]}],"execution_count":null},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"TwGAOAiKCKcr"}},{"cell_type":"code","source":["test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"],"metadata":{"id":"4vS6URwRCKcr","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:51.848703Z","iopub.status.idle":"2025-06-05T15:46:51.848961Z","shell.execute_reply.started":"2025-06-05T15:46:51.848838Z","shell.execute_reply":"2025-06-05T15:46:51.848849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 저장된 모델 로드\n","model_params = {'num_classes' : 196}\n","model = TResnetL368(model_params)\n","\n","net_layers = list(model.children())\n","classifier = net_layers[1:3]\n","net_layers = net_layers[0]\n","net_layers = list(net_layers.children())\n","\n","# Network_Wrapper 생성\n","model = Network_Wrapper(net_layers, len(class_names), classifier).to(device)\n","\n","model.load_state_dict(torch.load('best_model.pth', map_location=device))\n","model.to(device)\n","\n","# 추론\n","model.eval()\n","results = []\n","\n","with torch.no_grad():\n","    for images in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        probs = F.softmax(outputs, dim=1)\n","\n","        # 각 배치의 확률을 리스트로 변환\n","        for prob in probs.cpu():  # prob: (num_classes,)\n","            result = {\n","                class_names[i]: prob[i].item()\n","                for i in range(len(class_names))\n","            }\n","            results.append(result)\n","\n","pred = pd.DataFrame(results)"],"metadata":{"id":"i8XWppr-CKcr","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:51.85017Z","iopub.status.idle":"2025-06-05T15:46:51.850571Z","shell.execute_reply.started":"2025-06-05T15:46:51.850354Z","shell.execute_reply":"2025-06-05T15:46:51.850371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Submission"],"metadata":{"id":"HKj-nq9RCKcr"}},{"cell_type":"code","source":["submission = pd.read_csv(f'{arccyan_upscaled_car_datasets_path}/sample_submission.csv', encoding='utf-8-sig')\n","\n","# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n","class_columns = submission.columns[1:]\n","pred = pred[class_columns]\n","\n","submission[class_columns] = pred.values\n","submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"],"metadata":{"id":"9VcLATLfCKcr","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:51.851928Z","iopub.status.idle":"2025-06-05T15:46:51.852208Z","shell.execute_reply.started":"2025-06-05T15:46:51.852073Z","shell.execute_reply":"2025-06-05T15:46:51.852084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 자동 결과 로컬 저장\n","import pandas as pd\n","from IPython.display import Javascript\n","import json\n","\n","for i in range(1,CFG['EPOCHS']+1):\n","    acc_filepath = f'/content/TResNet/class_acc_epoch_{i}.csv'\n","    acc_file_name = f'class_acc_epoch_{i}.csv'\n","    detail_filepath = f'/content/TResNet/val_pred_detail_epoch_{i}.csv'\n","    detail_file_name = f'val_pred_detail_epoch_{i}.csv'\n","\n","    try:\n","        acc_df = pd.read_csv(acc_filepath)\n","        detail_df = pd.read_csv(detail_filepath)\n","        acc_csv_content = acc_df.to_csv(index=False)\n","        detail_csv_content = detail_df.to_csv(index=False)\n","\n","        detail_js_code = f\"\"\"\n","        console.log(\"다운로드 시도 중...\");\n","        var csv_content = {json.dumps(detail_csv_content)};\n","        var blob = new Blob([csv_content], {{type: 'text/csv;charset=utf-8;'}});\n","        var link = document.createElement(\"a\");\n","        var url = URL.createObjectURL(blob);\n","        link.setAttribute(\"href\", url);\n","        link.setAttribute(\"download\", \"{detail_file_name}\");\n","        link.style.visibility = 'hidden';\n","        document.body.appendChild(link);\n","        link.click();\n","        document.body.removeChild(link);\n","        console.log(\"다운로드 완료: {detail_file_name}\");\n","        \"\"\"\n","\n","        acc_js_code = f\"\"\"\n","        console.log(\"다운로드 시도 중...\");\n","        var csv_content = {json.dumps(acc_csv_content)};\n","        var blob = new Blob([csv_content], {{type: 'text/csv;charset=utf-8;'}});\n","        var link = document.createElement(\"a\");\n","        var url = URL.createObjectURL(blob);\n","        link.setAttribute(\"href\", url);\n","        link.setAttribute(\"download\", \"{acc_file_name}\");\n","        link.style.visibility = 'hidden';\n","        document.body.appendChild(link);\n","        link.click();\n","        document.body.removeChild(link);\n","        console.log(\"다운로드 완료: {acc_file_name}\");\n","        \"\"\"\n","\n","\n","        display(Javascript(detail_js_code))\n","        print(f\"✅ {detail_file_name} 다운로드 시작\")\n","        display(Javascript(acc_js_code))\n","        print(f\"✅ {acc_file_name} 다운로드 시작\")\n","\n","    except FileNotFoundError:\n","        print(f\"❌ {i}epoch 파일을 찾을 수 없습니다\")\n","    except Exception as e:\n","        print(f\"❌ 오류 발생 ({detail_file_name}): {e}\")\n","\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:51.853551Z","iopub.status.idle":"2025-06-05T15:46:51.854129Z","shell.execute_reply.started":"2025-06-05T15:46:51.853835Z","shell.execute_reply":"2025-06-05T15:46:51.853857Z"},"id":"VyvPZyzaEW2W"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["submission_csv_content = submission.to_csv(index=False)\n","submission_file_name = 'TResNet_random_crop_SAM_CELoss_best_submission.csv'\n","submission_js_code = f\"\"\"\n","console.log(\"다운로드 시도 중...\");\n","var csv_content = {json.dumps(submission_csv_content)};\n","var blob = new Blob([csv_content], {{type: 'text/csv;charset=utf-8;'}});\n","var link = document.createElement(\"a\");\n","var url = URL.createObjectURL(blob);\n","link.setAttribute(\"href\", url);\n","link.setAttribute(\"download\", \"{submission_file_name}\");\n","link.style.visibility = 'hidden';\n","document.body.appendChild(link);\n","link.click();\n","document.body.removeChild(link);\n","console.log(\"다운로드 완료: {submission_file_name}\");\n","\"\"\"\n","\n","display(Javascript(submission_js_code))\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T15:46:51.855262Z","iopub.status.idle":"2025-06-05T15:46:51.85558Z","shell.execute_reply.started":"2025-06-05T15:46:51.85543Z","shell.execute_reply":"2025-06-05T15:46:51.855446Z"},"id":"jRrK3qQXEW2W"},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"trusted":true,"id":"T-U1cRkcEW2W"},"outputs":[],"execution_count":null}]}