{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":11904337,"datasetId":7483280,"databundleVersionId":12410031},{"sourceType":"datasetVersion","sourceId":1771962,"datasetId":1053211,"databundleVersionId":1809293},{"sourceType":"datasetVersion","sourceId":11918208,"datasetId":7492523,"databundleVersionId":12425503},{"sourceType":"datasetVersion","sourceId":12062428,"datasetId":7583530,"databundleVersionId":12587153}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{"id":"L3oV47WeCKcn"}},{"cell_type":"code","source":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nfrom PIL import Image\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch import nn, optim\n\nfrom sklearn.metrics import log_loss\nimport wandb\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11180,"status":"ok","timestamp":1747893157421,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"5VRIs0HCCKco","outputId":"81c5c51f-7a68-430b-a8df-7ec278f2fa4b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install inplace-abn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Alibaba-MIIL/TResNet\n%cd TResNet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameter Setting","metadata":{"id":"6hXgRhYKCKcp"}},{"cell_type":"code","source":"CFG = {\n    'IMG_SIZE': 368,\n    'BATCH_SIZE': 32,\n    'EPOCHS': 10,\n    'LEARNING_RATE': 1e-4,\n    'SEED' : 42\n}","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1747893157442,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"xvRCnuRqCKcp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wandb login 1128bf290760f1cd846378e87ab026431fee90c3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize wandb\nwandb.init(\n    entity='Dacon_Car',\n    project=\"car-classification\",  # your project name\n    name='TResNet_cutout',\n    config=CFG  # this will log your hyperparameters\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fixed RandomSeed","metadata":{"id":"ullOr-KjCKcp"}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)    \n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG['SEED']) # Seed ê³ ì •","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1747893157484,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"Uwop2i4qCKcp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CustomDataset","metadata":{"id":"AUwzuA7jCKcq"}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np # NumPy ì„í¬íŠ¸ ì¶”ê°€\nfrom torch.utils.data import Dataset\n# albumentationsì™€ ToTensorV2 ì„í¬íŠ¸ëŠ” Dataset í´ë˜ìŠ¤ ì™¸ë¶€ì—ì„œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None, is_test=False):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.samples = []\n\n        if is_test:\n            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n            for fname in sorted(os.listdir(root_dir)):\n                if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # ì´ë¯¸ì§€ í™•ì¥ì ì¶”ê°€\n                    img_path = os.path.join(root_dir, fname)\n                    self.samples.append((img_path,))\n        else:\n            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n            self.classes = sorted(os.listdir(root_dir))\n            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n\n            for cls_name in self.classes:\n                cls_folder = os.path.join(root_dir, cls_name)\n                # í´ë”ê°€ ì•„ë‹Œ íŒŒì¼ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ isdir ì²´í¬ ì¶”ê°€\n                if not os.path.isdir(cls_folder):\n                    continue\n                for fname in os.listdir(cls_folder):\n                    if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # ì´ë¯¸ì§€ í™•ì¥ì ì¶”ê°€\n                        img_path = os.path.join(cls_folder, fname)\n                        label = self.class_to_idx[cls_name]\n                        self.samples.append((img_path, label))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        if self.is_test:\n            img_path = self.samples[idx][0]\n            image = Image.open(img_path).convert('RGB')\n            # PIL ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜\n            image = np.array(image)\n\n            if self.transform:\n                # AlbumentationsëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ë©° 'image' í‚¤ì— ë³€í™˜ëœ ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n                transformed_data = self.transform(image=image)\n                image = transformed_data['image'] # PyTorch í…ì„œ (C, H, W)\n\n            return image\n        else:\n            img_path, label = self.samples[idx]\n            image = Image.open(img_path).convert('RGB')\n            # PIL ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜\n            image = np.array(image)\n\n            if self.transform:\n                # AlbumentationsëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ë©° 'image' í‚¤ì— ë³€í™˜ëœ ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n                transformed_data = self.transform(image=image)\n                image = transformed_data['image'] # PyTorch í…ì„œ (C, H, W)\n\n            return image, label","metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1747893157488,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"EOA2BdsbCKcq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Load","metadata":{"id":"6bmib4EdCKcq"}},{"cell_type":"code","source":"train_root = '/kaggle/input/vehicle-upscaled/upscaled/upscaled/train'\ntest_root = '/kaggle/input/vehicle-upscaled/upscaled_test/upscaled/test'","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1747893157492,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"GLNBNSyDCKcq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade albumentations","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2 # PyTorch í…ì„œë¡œ ë³€í™˜í•˜ê¸° ìœ„í•¨\nimport numpy as np # AlbumentationsëŠ” NumPy ë°°ì—´ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.\nfrom PIL import Image # ì´ë¯¸ì§€ ë¡œë”©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n\n# Albumentationsì˜ train_transform\ntrain_transform = A.Compose([\n    # ResizeIfPadNeededëŠ” ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ì˜ ê¸´ ë³€ ë˜ëŠ” ì§§ì€ ë³€ì„ ë¦¬ì‚¬ì´ì¦ˆí•œ ë‹¤ìŒ,\n    # ì§€ì •ëœ í¬ê¸°ì— ë§ì¶° íŒ¨ë”©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n    # pad_height, pad_widthëŠ” ìµœì¢… ì¶œë ¥ í¬ê¸°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n    # ë§Œì•½ ì›ë³¸ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ íŒ¨ë”©ìœ¼ë¡œ ì±„ìš°ëŠ” ê²ƒì´ ëª©ì ì´ë¼ë©´ ì•„ë˜ì™€ ê°™ì´ LongestMaxSizeì™€ PadIfNeededë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n    A.LongestMaxSize(max_size=CFG['IMG_SIZE'], interpolation=Image.BILINEAR),\n    A.PadIfNeeded(min_height=CFG['IMG_SIZE'], min_width=CFG['IMG_SIZE'],\n                border_mode=0, fill=(0,0,0)), # border_mode=0 (CONSTANT), valueëŠ” íŒ¨ë”© ìƒ‰ìƒ\n\n    # ì¼ë°˜ì ìœ¼ë¡œ í•™ìŠµ ì‹œì—ëŠ” Resize í›„ Normalizeë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n    # torchvisionì˜ Normalizeì™€ ë™ì¼í•œ mean/std ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n    A.Normalize(mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0), # ì´ë¯¸ì§€ í”½ì…€ ê°’ì˜ ìµœëŒ“ê°’ (ì¼ë°˜ì ìœ¼ë¡œ 255)\n\n    # Albumentationsì˜ ToTensorV2ëŠ” ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜í•˜ê³  ì±„ë„ ìˆœì„œë¥¼ (H, W, C) -> (C, H, W)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n    # torchvisionì˜ ToTensor()ì™€ ìœ ì‚¬í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.\n    ToTensorV2()\n])  \n\n# Albumentationsì˜ val_transform (train_transformê³¼ ë™ì¼í•˜ê²Œ êµ¬ì„±)\nval_transform = A.Compose([\n    # ê²€ì¦ ì‹œì—ë„ ë™ì¼í•˜ê²Œ Resize ë° Normalizeë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n    A.LongestMaxSize(max_size=CFG['IMG_SIZE'], interpolation=Image.BILINEAR),\n    A.PadIfNeeded(min_height=CFG['IMG_SIZE'], min_width=CFG['IMG_SIZE'],\n                border_mode=0, fill=(0,0,0)), # border_mode=0 (CONSTANT), valueëŠ” íŒ¨ë”© ìƒ‰ìƒ\n    A.Normalize(mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0),\n    ToTensorV2()    \n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\nfull_dataset = CustomImageDataset(train_root, transform=None)\nprint(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n\ntargets = [label for _, label in full_dataset.samples]\nclass_names = full_dataset.classes\n\n# Stratified Split\ntrain_idx, val_idx = train_test_split(\n    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n)\n\n# Subset + transform ê°ê° ì ìš©  \ntrain_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\nval_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\nprint(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n\n\n# DataLoader ì •ì˜\ntrain_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Define","metadata":{"id":"fM0RBKa5CKcr"}},{"cell_type":"code","source":"from src.models.tresnet_v2.tresnet_v2 import TResnetL_V2 as TResnetL368\n\n\nclass TResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(TResNet, self).__init__()\n        model_params = {'num_classes' : 196}\n        self.backbone = TResnetL368(model_params)\n        \n        weights_path = \"/kaggle/input/tresnet-stanford-cars-pretrained/stanford_cars_tresnet-l-v2_96_27.pth\"\n        pretrained_weights = torch.load(weights_path)\n        \n        self.backbone.load_state_dict(pretrained_weights['model'])  # TResnetL368 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n        self.feature_dim = self.backbone.num_features\n        self.backbone.head = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.head(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn.modules.batchnorm import _BatchNorm\n\ndef cosine_anneal_schedule(t, nb_epoch, lr):\n    cos_inner = np.pi * (t % (nb_epoch))\n    cos_inner /= (nb_epoch)\n    cos_out = np.cos(cos_inner) + 1\n\n    return float(lr / 2 * cos_out)\n\nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n                                 momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\nclass Features(nn.Module):\n    def __init__(self, net_layers_FeatureHead):\n        super(Features, self).__init__()\n        self.net_layer_0 = nn.Sequential(net_layers_FeatureHead[0])\n        self.net_layer_1 = nn.Sequential(*net_layers_FeatureHead[1])\n        self.net_layer_2 = nn.Sequential(*net_layers_FeatureHead[2])\n        self.net_layer_3 = nn.Sequential(*net_layers_FeatureHead[3])\n        self.net_layer_4 = nn.Sequential(*net_layers_FeatureHead[4])\n        self.net_layer_5 = nn.Sequential(*net_layers_FeatureHead[5])\n\n    def forward(self, x):\n        x = self.net_layer_0(x)\n        x = self.net_layer_1(x)\n        x = self.net_layer_2(x)\n        x1 = self.net_layer_3(x)\n        x2 = self.net_layer_4(x1)\n        x3 = self.net_layer_5(x2)\n\n        return x1, x2, x3\n\n\nclass Network_Wrapper(nn.Module):\n    def __init__(self, net_layers, num_classes, classifier):\n        super().__init__()\n        self.Features = Features(net_layers)\n        self.classifier_pool = nn.Sequential(classifier[0])\n        \n        # classifier_initialì„ num_classesì— ë§ê²Œ ìˆ˜ì •\n        self.classifier_initial = nn.Linear(2048, num_classes)  # ê¸°ì¡´ 196ì„ num_classesë¡œ ë³€ê²½\n        \n        self.sigmoid = nn.Sigmoid()\n        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n\n        self.max_pool1 = nn.MaxPool2d(kernel_size=46, stride=1)\n        self.max_pool2 = nn.MaxPool2d(kernel_size=23, stride=1)\n        self.max_pool3 = nn.MaxPool2d(kernel_size=12, stride=1)\n\n        self.conv_block1 = nn.Sequential(\n            BasicConv(512, 512, kernel_size=1, stride=1, padding=0, relu=True),\n            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n        )\n        self.classifier1 = nn.Sequential(\n            nn.BatchNorm1d(1024),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ELU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n\n        self.conv_block2 = nn.Sequential(\n            BasicConv(1024, 512, kernel_size=1, stride=1, padding=0, relu=True),\n            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n        )\n        self.classifier2 = nn.Sequential(\n            nn.BatchNorm1d(1024),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ELU(inplace=True),\n            nn.Linear(512, num_classes),\n        )\n\n        self.conv_block3 = nn.Sequential(\n            BasicConv(2048, 512, kernel_size=1, stride=1, padding=0, relu=True),\n            BasicConv(512, 1024, kernel_size=3, stride=1, padding=1, relu=True)\n        )\n        self.classifier3 = nn.Sequential(\n            nn.BatchNorm1d(1024),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ELU(inplace=True),\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        _, _, x3 = self.Features(x) # , x2, x3\n        # map1 = x1.clone()\n        # map2 = x2.clone()\n        # map3 = x3.clone()\n\n        classifiers = self.classifier_pool(x3).view(x3.size(0), -1)\n        classifiers = self.classifier_initial(classifiers)  # ì´ì œ num_classes ì¶œë ¥\n\n        # x1_ = self.conv_block1(x1)\n        # x1_ = self.max_pool1(x1_)\n        # x1_f = x1_.view(x1_.size(0), -1)\n\n        # x1_c = self.classifier1(x1_f)\n\n        # x2_ = self.conv_block2(x2)\n        # x2_ = self.max_pool2(x2_)\n        # x2_f = x2_.view(x2_.size(0), -1)\n        # x2_c = self.classifier2(x2_f)\n\n        # x3_ = self.conv_block3(x3)\n        # x3_ = self.max_pool3(x3_)\n        # x3_f = x3_.view(x3_.size(0), -1)\n        # x3_c = self.classifier3(x3_f)\n\n        return classifiers #x1_c , x2_c, x3_c , map1, map2, map3\n\n\nclass Anti_Noise_Decoder(nn.Module):\n    def __init__(self, scale, in_channel):\n        super(Anti_Noise_Decoder, self).__init__()\n        self.Sigmoid = nn.Sigmoid()\n\n        in_channel = in_channel // (scale * scale)\n\n        self.skip = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n            nn.Conv2d(64, 3, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True)\n\n        )\n\n        self.process = nn.Sequential(\n            nn.PixelShuffle(scale),\n            nn.Conv2d(in_channel, 256, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n            nn.PixelShuffle(2),\n            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n            nn.PixelShuffle(2),\n            nn.Conv2d(32, 64, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True),\n            nn.PixelShuffle(2),\n            nn.Conv2d(16, 3, 3, 1, 1, bias=False),\n            nn.LeakyReLU(negative_slope=0.1, inplace=True)\n        )\n\n    def forward(self, x, map):\n        x_ = self.process(map)\n        if not (x.size() == x_.size()):\n            x_ = F.interpolate(x, (x.size(2),x.size(3)), mode='bilinear')\n        return self.skip(x) + x_\n\n\ndef img_add_noise(x, transformation_seq):\n    x = x.permute(0, 2, 3, 1)\n    x = x.cpu().numpy()\n    x = transformation_seq(images=x)\n    x = torch.from_numpy(x.astype(np.float32))\n    x = x.permute(0, 3, 1, 2)\n    return x\n\ndef smooth_crossentropy(pred, gold, smoothing=0.1):\n    n_class = pred.size(1)\n\n    one_hot = torch.full_like(pred, fill_value=smoothing / (n_class - 1))\n    one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - smoothing)\n    log_prob = F.log_softmax(pred, dim=1)\n\n    return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1)\n\ndef CELoss(x, y):\n    return smooth_crossentropy(x, y, smoothing=0.1)\n\nclass CharbonnierLoss(nn.Module):\n    \"\"\"Charbonnier Loss (L1)\"\"\"\n\n    def __init__(self, eps=1e-3):\n        super(CharbonnierLoss, self).__init__()\n        self.eps = eps\n\n    def forward(self, x, y):\n        diff = x - y\n        # loss = torch.sum(torch.sqrt(diff * diff + self.eps))\n        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps*self.eps)))\n        return loss\n    \n\n\n\ndef disable_running_stats(model):\n    def _disable(module):\n        if isinstance(module, _BatchNorm):\n            module.backup_momentum = module.momentum\n            module.momentum = 0\n\n    model.apply(_disable)\n\ndef enable_running_stats(model):\n    def _enable(module):\n        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n            module.momentum = module.backup_momentum\n\n    model.apply(_enable)\n\n\nclass Student_Wrapper(nn.Module):\n    def __init__(self, net_layers, classifier):\n        super(Student_Wrapper, self).__init__()\n        self.net_layer_0 = nn.Sequential(net_layers[0])\n        self.net_layer_1 = nn.Sequential(*net_layers[1])\n        self.net_layer_2 = nn.Sequential(*net_layers[2])\n        self.net_layer_3 = nn.Sequential(*net_layers[3])\n        self.net_layer_4 = nn.Sequential(*net_layers[4])\n        self.net_layer_5 = nn.Sequential(*net_layers[5])\n\n        self.classifier_pool = nn.Sequential(classifier[0])\n        self.classifier_initial = nn.Sequential(classifier[1])\n\n    def forward(self, x):\n        x = self.net_layer_0(x)\n        x = self.net_layer_1(x)\n        x = self.net_layer_2(x)\n        x1 = self.net_layer_3(x)\n        x2 = self.net_layer_4(x1)\n        x3 = self.net_layer_5(x2)\n\n\n        classifiers = self.classifier_pool(x3).view(x3.size(0), -1)\n        out = self.classifier_initial(classifiers)\n\n        return out, x1, x2, x3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SAM\nclass SAM(torch.optim.Optimizer):\n    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n        self.defaults.update(self.base_optimizer.defaults)\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = group[\"rho\"] / (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                self.state[p][\"old_p\"] = p.data.clone()\n                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n\n        self.first_step(zero_grad=True)\n        closure()\n        self.second_step()\n\n    def _grad_norm(self):\n        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n        norm = torch.norm(\n                    torch.stack([\n                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n                        for group in self.param_groups for p in group[\"params\"]\n                        if p.grad is not None\n                    ]),\n                    p=2\n               )\n        return norm\n\n    def load_state_dict(self, state_dict):\n        super().load_state_dict(state_dict)\n        self.base_optimizer.param_groups = self.param_groups","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train/ Validation","metadata":{"id":"NGlK2nPYCKcr"}},{"cell_type":"code","source":"# model = TResNet(num_classes=len(class_names)).to(device)\nbest_logloss = float('inf')\n\n# ì†ì‹¤ í•¨ìˆ˜\ncriterion = nn.CrossEntropyLoss()\n\n# PMAL\nmodel_params = {'num_classes' : 196}\nmodel = TResnetL368(model_params)\nweights_path = \"/kaggle/input/tresnet-stanford-cars-pretrained/stanford_cars_tresnet-l-v2_96_27.pth\"\npretrained_weights = torch.load(weights_path)\nmodel.load_state_dict(pretrained_weights['model'])\n\nnet_layers = list(model.children())\nclassifier = net_layers[1:3]\nnet_layers = net_layers[0]\nnet_layers = list(net_layers.children())\n\n# Network_Wrapper ìƒì„±\nmodel = Network_Wrapper(net_layers, len(class_names), classifier).to(device)\n\n# ì˜µí‹°ë§ˆì´ì €\noptimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n\n# í•™ìŠµ ë° ê²€ì¦ ë£¨í”„\nfor epoch in range(CFG['EPOCHS']):\n    # Train\n    model.train()\n    train_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)  # logits\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    all_probs = []\n    all_labels = []\n    all_pred_labels = []\n    class_correct = [0 for _ in range(len(class_names))]\n    class_total = [0 for _ in range(len(class_names))]\n    \n\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Accuracy\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n            for label, pred in zip(labels.cpu().numpy(), preds.cpu().numpy()):\n                class_total[label] += 1\n                if label == pred:\n                    class_correct[label] += 1\n            \n\n            # LogLoss\n            probs = F.softmax(outputs, dim=1)\n            all_probs.extend(probs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_pred_labels.extend(preds.cpu().numpy())\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_accuracy = 100 * correct / total\n    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n\n    class_acc = [c / t if t > 0 else 0 for c, t in zip(class_correct, class_total)]\n    df_class_acc = pd.DataFrame({\n        'Class Name': class_names,\n        'Correct': class_correct,\n        'Total': class_total,\n        'Accuracy': class_acc\n    }).sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n\n    df_pred_detail = pd.DataFrame({\n        'TrueLabel': all_labels,\n        'PredLabel': all_pred_labels,\n        'TrueClass': [class_names[i] for i in all_labels],\n        'PredClass': [class_names[i] for i in all_pred_labels]\n    })\n    df_pred_detail.to_csv(f'val_pred_detail_epoch_{epoch+1}.csv', index=False, encoding='utf-8-sig')\n    # epoch ë²ˆí˜¸ë¥¼ íŒŒì¼ëª…ì— í¬í•¨í•˜ì—¬ ì €ì¥\n    df_class_acc.to_csv(f'class_acc_epoch_{epoch+1}.csv', index=False, encoding='utf-8-sig')\n    # wandb \n    wandb.log({\n        \"train_loss\": avg_train_loss,\n        \"val_loss\": avg_val_loss,\n        \"val_accuracy\": val_accuracy,\n        \"val_logloss\": val_logloss\n    })\n    \n    # ê²°ê³¼ ì¶œë ¥\n    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n\n    # Best model ì €ì¥\n    if val_logloss < best_logloss:\n        best_logloss = val_logloss\n        torch.save(model.state_dict(), f'best_model.pth')\n        print(f\"ğŸ“¦ Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"elapsed":263293,"status":"error","timestamp":1747893498648,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"DwNWkTC3CKcr","outputId":"c3e4f7fa-70b2-4225-bcc9-b185a00f9f99","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"TwGAOAiKCKcr"}},{"cell_type":"code","source":"test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)","metadata":{"executionInfo":{"elapsed":379040,"status":"aborted","timestamp":1747893498644,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"4vS6URwRCKcr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\nmodel_params = {'num_classes' : 196}\nmodel = TResnetL368(model_params)\n\nnet_layers = list(model.children())\nclassifier = net_layers[1:3]\nnet_layers = net_layers[0]\nnet_layers = list(net_layers.children())\n\n# Network_Wrapper ìƒì„±\nmodel = Network_Wrapper(net_layers, len(class_names), classifier).to(device)\n\nmodel.load_state_dict(torch.load('best_model.pth', map_location=device))\nmodel.to(device)\n\n# ì¶”ë¡ \nmodel.eval()\nresults = []\n\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        probs = F.softmax(outputs, dim=1)\n\n        # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n        for prob in probs.cpu():  # prob: (num_classes,)\n            result = {\n                class_names[i]: prob[i].item()\n                for i in range(len(class_names))\n            }\n            results.append(result)\n\npred = pd.DataFrame(results)","metadata":{"executionInfo":{"elapsed":379037,"status":"aborted","timestamp":1747893498646,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"i8XWppr-CKcr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{"id":"HKj-nq9RCKcr"}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/car-classification/sample_submission.csv', encoding='utf-8-sig')\n\n# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\nclass_columns = submission.columns[1:]\npred = pred[class_columns]\n\nsubmission[class_columns] = pred.values\nsubmission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')","metadata":{"executionInfo":{"elapsed":379034,"status":"aborted","timestamp":1747893498647,"user":{"displayName":"ë°•ì§„ì˜","userId":"15299328254354703813"},"user_tz":-540},"id":"9VcLATLfCKcr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}