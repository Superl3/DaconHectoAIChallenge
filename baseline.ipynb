{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3oV47WeCKcn"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-29T06:04:50.949687Z",
     "iopub.status.busy": "2025-05-29T06:04:50.948997Z",
     "iopub.status.idle": "2025-05-29T06:04:56.617764Z",
     "shell.execute_reply": "2025-05-29T06:04:56.617051Z",
     "shell.execute_reply.started": "2025-05-29T06:04:50.949657Z"
    },
    "executionInfo": {
     "elapsed": 11180,
     "status": "ok",
     "timestamp": 1747893157421,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "5VRIs0HCCKco",
    "outputId": "81c5c51f-7a68-430b-a8df-7ec278f2fa4b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import wandb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:04:56.622335Z",
     "iopub.status.busy": "2025-05-29T06:04:56.622095Z",
     "iopub.status.idle": "2025-05-29T06:04:59.597452Z",
     "shell.execute_reply": "2025-05-29T06:04:59.596453Z",
     "shell.execute_reply.started": "2025-05-29T06:04:56.622308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inplace-abn in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install inplace-abn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:04:59.598601Z",
     "iopub.status.busy": "2025-05-29T06:04:59.598381Z",
     "iopub.status.idle": "2025-05-29T06:04:59.740397Z",
     "shell.execute_reply": "2025-05-29T06:04:59.739508Z",
     "shell.execute_reply.started": "2025-05-29T06:04:59.598578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TResNet' already exists and is not an empty directory.\n",
      "/kaggle/working/TResNet\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Alibaba-MIIL/TResNet\n",
    "%cd TResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hXgRhYKCKcp"
   },
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:04:59.742187Z",
     "iopub.status.busy": "2025-05-29T06:04:59.741601Z",
     "iopub.status.idle": "2025-05-29T06:04:59.746143Z",
     "shell.execute_reply": "2025-05-29T06:04:59.745315Z",
     "shell.execute_reply.started": "2025-05-29T06:04:59.742157Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747893157442,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "xvRCnuRqCKcp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 368,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:04:59.747191Z",
     "iopub.status.busy": "2025-05-29T06:04:59.746894Z",
     "iopub.status.idle": "2025-05-29T06:05:03.963200Z",
     "shell.execute_reply": "2025-05-29T06:05:03.962160Z",
     "shell.execute_reply.started": "2025-05-29T06:04:59.747164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:03.964773Z",
     "iopub.status.busy": "2025-05-29T06:05:03.964455Z",
     "iopub.status.idle": "2025-05-29T06:05:16.747662Z",
     "shell.execute_reply": "2025-05-29T06:05:16.746980Z",
     "shell.execute_reply.started": "2025-05-29T06:05:03.964735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msingiri129\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/TResNet/wandb/run-20250529_060510-z676fiel</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Dacon_Car/car-classification/runs/z676fiel' target=\"_blank\">expert-glitter-5</a></strong> to <a href='https://wandb.ai/Dacon_Car/car-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Dacon_Car/car-classification' target=\"_blank\">https://wandb.ai/Dacon_Car/car-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Dacon_Car/car-classification/runs/z676fiel' target=\"_blank\">https://wandb.ai/Dacon_Car/car-classification/runs/z676fiel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/Dacon_Car/car-classification/runs/z676fiel?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ce6a07f6310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    entity='Dacon_Car',\n",
    "    project=\"car-classification\",  # your project name\n",
    "    name='TResNet',\n",
    "    config=CFG  # this will log your hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ullOr-KjCKcp"
   },
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:16.748578Z",
     "iopub.status.busy": "2025-05-29T06:05:16.748397Z",
     "iopub.status.idle": "2025-05-29T06:05:16.756491Z",
     "shell.execute_reply": "2025-05-29T06:05:16.755850Z",
     "shell.execute_reply.started": "2025-05-29T06:05:16.748562Z"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1747893157484,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "Uwop2i4qCKcp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed Í≥†Ï†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUwzuA7jCKcq"
   },
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:16.757402Z",
     "iopub.status.busy": "2025-05-29T06:05:16.757181Z",
     "iopub.status.idle": "2025-05-29T06:05:16.769229Z",
     "shell.execute_reply": "2025-05-29T06:05:16.768681Z",
     "shell.execute_reply.started": "2025-05-29T06:05:16.757384Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1747893157488,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "EOA2BdsbCKcq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np # NumPy ÏûÑÌè¨Ìä∏ Ï∂îÍ∞Ä\n",
    "from torch.utils.data import Dataset\n",
    "# albumentationsÏôÄ ToTensorV2 ÏûÑÌè¨Ìä∏Îäî Dataset ÌÅ¥ÎûòÏä§ Ïô∏Î∂ÄÏóêÏÑú Ïù¥Î£®Ïñ¥Ï†∏Ïïº Ìï©ÎãàÎã§.\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # ÌÖåÏä§Ìä∏ÏÖã: ÎùºÎ≤® ÏóÜÏù¥ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎßå Ï†ÄÏû•\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # Ïù¥ÎØ∏ÏßÄ ÌôïÏû•Ïûê Ï∂îÍ∞Ä\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # ÌïôÏäµÏÖã: ÌÅ¥ÎûòÏä§Î≥Ñ Ìè¥Îçî Íµ¨Ï°∞ÏóêÏÑú ÎùºÎ≤® Ï∂îÏ∂ú\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                # Ìè¥ÎçîÍ∞Ä ÏïÑÎãå ÌååÏùºÏù¥ ÏûàÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú isdir Ï≤¥ÌÅ¨ Ï∂îÍ∞Ä\n",
    "                if not os.path.isdir(cls_folder):\n",
    "                    continue\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')): # Ïù¥ÎØ∏ÏßÄ ÌôïÏû•Ïûê Ï∂îÍ∞Ä\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            # PIL Ïù¥ÎØ∏ÏßÄÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôò\n",
    "            image = np.array(image)\n",
    "\n",
    "            if self.transform:\n",
    "                # AlbumentationsÎäî ÎîïÏÖîÎÑàÎ¶¨Î•º Î∞òÌôòÌïòÎ©∞ 'image' ÌÇ§Ïóê Î≥ÄÌôòÎêú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÏäµÎãàÎã§.\n",
    "                transformed_data = self.transform(image=image)\n",
    "                image = transformed_data['image'] # PyTorch ÌÖêÏÑú (C, H, W)\n",
    "\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            # PIL Ïù¥ÎØ∏ÏßÄÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôò\n",
    "            image = np.array(image)\n",
    "\n",
    "            if self.transform:\n",
    "                # AlbumentationsÎäî ÎîïÏÖîÎÑàÎ¶¨Î•º Î∞òÌôòÌïòÎ©∞ 'image' ÌÇ§Ïóê Î≥ÄÌôòÎêú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÏäµÎãàÎã§.\n",
    "                transformed_data = self.transform(image=image)\n",
    "                image = transformed_data['image'] # PyTorch ÌÖêÏÑú (C, H, W)\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bmib4EdCKcq"
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:16.770182Z",
     "iopub.status.busy": "2025-05-29T06:05:16.769986Z",
     "iopub.status.idle": "2025-05-29T06:05:16.789696Z",
     "shell.execute_reply": "2025-05-29T06:05:16.789076Z",
     "shell.execute_reply.started": "2025-05-29T06:05:16.770168Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1747893157492,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "GLNBNSyDCKcq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_root = '/kaggle/input/car-classification/train'\n",
    "test_root = '/kaggle/input/car-classification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:16.810089Z",
     "iopub.status.busy": "2025-05-29T06:05:16.809826Z",
     "iopub.status.idle": "2025-05-29T06:05:16.826773Z",
     "shell.execute_reply": "2025-05-29T06:05:16.826104Z",
     "shell.execute_reply.started": "2025-05-29T06:05:16.810067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 # PyTorch ÌÖêÏÑúÎ°ú Î≥ÄÌôòÌïòÍ∏∞ ÏúÑÌï®\n",
    "import numpy as np # AlbumentationsÎäî NumPy Î∞∞Ïó¥ÏùÑ ÏûÖÎ†•ÏúºÎ°ú Î∞õÏäµÎãàÎã§.\n",
    "from PIL import Image # Ïù¥ÎØ∏ÏßÄ Î°úÎî©ÏùÑ ÏúÑÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "\n",
    "# AlbumentationsÏùò train_transform\n",
    "train_transform = A.Compose([\n",
    "    # ResizeIfPadNeededÎäî Í∞ÄÎ°úÏÑ∏Î°ú ÎπÑÏú®ÏùÑ Ïú†ÏßÄÌïòÎ©¥ÏÑú Ïù¥ÎØ∏ÏßÄÏùò Í∏¥ Î≥Ä ÎòêÎäî ÏßßÏùÄ Î≥ÄÏùÑ Î¶¨ÏÇ¨Ïù¥Ï¶àÌïú Îã§Ïùå,\n",
    "    # ÏßÄÏ†ïÎêú ÌÅ¨Í∏∞Ïóê ÎßûÏ∂∞ Ìå®Îî©ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
    "    # pad_height, pad_widthÎäî ÏµúÏ¢Ö Ï∂úÎ†• ÌÅ¨Í∏∞Î•º ÏùòÎØ∏Ìï©ÎãàÎã§.\n",
    "    A.Resize(height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE'], interpolation=Image.BILINEAR), # Î®ºÏ†Ä target sizeÎ°ú resize\n",
    "    # ResizeIfPadNeededÏùò ÏßÅÏ†ëÏ†ÅÏù∏ ÎåÄÏ≤¥Ï†úÎäî ÏóÜÏßÄÎßå,\n",
    "    # A.LongestMaxSize ÎòêÎäî A.SmallestMaxSizeÎ•º Î®ºÏ†Ä ÏÇ¨Ïö©ÌïòÍ≥† A.PadIfNeededÎ•º Ï°∞Ìï©ÌïòÎäî Í≤ÉÏù¥ Í∞ÄÏû• Ïú†ÏÇ¨Ìï©ÎãàÎã§.\n",
    "    # Ïó¨Í∏∞ÏÑúÎäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÎßéÏù¥ ÏÇ¨Ïö©ÎêòÎäî ResizeÎ•º Î®ºÏ†Ä ÏÇ¨Ïö©ÌïòÍ≥†,\n",
    "    # Ïù¥ÌõÑ A.PadIfNeededÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏõêÎ≥∏ ÎπÑÏú®ÏùÑ Ïú†ÏßÄÌïòÎ©∞ Ìå®Îî©ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
    "    # ÎßåÏïΩ ÏõêÎ≥∏ ÎπÑÏú®ÏùÑ Ïú†ÏßÄÌïòÎ©¥ÏÑú Ìå®Îî©ÏúºÎ°ú Ï±ÑÏö∞Îäî Í≤ÉÏù¥ Î™©Ï†ÅÏù¥ÎùºÎ©¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ LongestMaxSizeÏôÄ PadIfNeededÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "        A.LongestMaxSize(max_size=CFG['IMG_SIZE'], interpolation=Image.BILINEAR),\n",
    "        A.PadIfNeeded(min_height=CFG['IMG_SIZE'], min_width=CFG['IMG_SIZE'],\n",
    "                    border_mode=0, value=(0,0,0)), # border_mode=0 (CONSTANT), valueÎäî Ìå®Îî© ÏÉâÏÉÅ\n",
    "\n",
    "    # ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÌïôÏäµ ÏãúÏóêÎäî Resize ÌõÑ NormalizeÎ•º ÎßéÏù¥ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "    # torchvisionÏùò NormalizeÏôÄ ÎèôÏùºÌïú mean/std Í∞íÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0), # Ïù¥ÎØ∏ÏßÄ ÌîΩÏÖÄ Í∞íÏùò ÏµúÎåìÍ∞í (ÏùºÎ∞òÏ†ÅÏúºÎ°ú 255)\n",
    "\n",
    "    # AlbumentationsÏùò ToTensorV2Îäî Ïù¥ÎØ∏ÏßÄÎ•º PyTorch ÌÖêÏÑúÎ°ú Î≥ÄÌôòÌïòÍ≥† Ï±ÑÎÑê ÏàúÏÑúÎ•º (H, W, C) -> (C, H, W)Î°ú Î≥ÄÍ≤ΩÌï©ÎãàÎã§.\n",
    "    # torchvisionÏùò ToTensor()ÏôÄ Ïú†ÏÇ¨ÌïòÍ≤å ÎèôÏûëÌï©ÎãàÎã§.\n",
    "    ToTensorV2()\n",
    "])  \n",
    "\n",
    "# AlbumentationsÏùò val_transform (train_transformÍ≥º ÎèôÏùºÌïòÍ≤å Íµ¨ÏÑ±)\n",
    "val_transform = A.Compose([\n",
    "    # Í≤ÄÏ¶ù ÏãúÏóêÎèÑ ÎèôÏùºÌïòÍ≤å Resize Î∞è NormalizeÎ•º Ï†ÅÏö©Ìï©ÎãàÎã§.\n",
    "    A.Resize(height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE'], interpolation=Image.BILINEAR),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0),\n",
    "    ToTensorV2()    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:16.837403Z",
     "iopub.status.busy": "2025-05-29T06:05:16.837145Z",
     "iopub.status.idle": "2025-05-29T06:05:17.727413Z",
     "shell.execute_reply": "2025-05-29T06:05:17.726729Z",
     "shell.execute_reply.started": "2025-05-29T06:05:16.837382Z"
    },
    "executionInfo": {
     "elapsed": 77833,
     "status": "ok",
     "timestamp": 1747893235336,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "Og91skMBCKcr",
    "outputId": "5b71c48e-9955-45f2-cf63-4b7e3fa304de",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: 33137\n",
      "train Ïù¥ÎØ∏ÏßÄ Ïàò: 26509, valid Ïù¥ÎØ∏ÏßÄ Ïàò: 6628\n"
     ]
    }
   ],
   "source": [
    "# Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform Í∞ÅÍ∞Å Ï†ÅÏö©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train Ïù¥ÎØ∏ÏßÄ Ïàò: {len(train_dataset)}, valid Ïù¥ÎØ∏ÏßÄ Ïàò: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader Ï†ïÏùò\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM0RBKa5CKcr"
   },
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:17.733632Z",
     "iopub.status.busy": "2025-05-29T06:05:17.733294Z",
     "iopub.status.idle": "2025-05-29T06:05:17.772893Z",
     "shell.execute_reply": "2025-05-29T06:05:17.772357Z",
     "shell.execute_reply.started": "2025-05-29T06:05:17.733608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.models.tresnet_v2.tresnet_v2 import TResnetL_V2 as TResnetL368\n",
    "\n",
    "\n",
    "class TResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TResNet, self).__init__()\n",
    "        model_params = {'num_classes' : 196}\n",
    "        self.backbone = TResnetL368(model_params)\n",
    "        \n",
    "        weights_path = \"/kaggle/input/tresnet-stanford-cars-pretrained/stanford_cars_tresnet-l-v2_96_27.pth\"\n",
    "        pretrained_weights = torch.load(weights_path)\n",
    "        \n",
    "        self.backbone.load_state_dict(pretrained_weights['model'])  # TResnetL368 Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        self.backbone.head = nn.Identity()  # feature extractorÎ°úÎßå ÏÇ¨Ïö©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # Î∂ÑÎ•òÍ∏∞\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGlK2nPYCKcr"
   },
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "execution": {
     "iopub.execute_input": "2025-05-29T06:05:17.774053Z",
     "iopub.status.busy": "2025-05-29T06:05:17.773717Z"
    },
    "executionInfo": {
     "elapsed": 263293,
     "status": "error",
     "timestamp": 1747893498648,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "DwNWkTC3CKcr",
    "outputId": "c3e4f7fa-70b2-4225-bcc9-b185a00f9f99",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Training:   3%|‚ñé         | 28/829 [00:39<19:01,  1.43s/it]"
     ]
    }
   ],
   "source": [
    "model = TResNet(num_classes=len(class_names)).to(device)\n",
    "best_logloss = float('inf')\n",
    "\n",
    "# ÏÜêÏã§ Ìï®Ïàò\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ÏòµÌã∞ÎßàÏù¥Ï†Ä\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "# ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Î£®ÌîÑ\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "    \n",
    "    # wandb \n",
    "    wandb.log({\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"val_logloss\": val_logloss\n",
    "    })\n",
    "    \n",
    "    # Í≤∞Í≥º Ï∂úÎ†•\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
    "\n",
    "    # Best model Ï†ÄÏû•\n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        torch.save(model.state_dict(), f'best_model.pth')\n",
    "        print(f\"üì¶ Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwGAOAiKCKcr"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 379040,
     "status": "aborted",
     "timestamp": 1747893498644,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "4vS6URwRCKcr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 379037,
     "status": "aborted",
     "timestamp": 1747893498646,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "i8XWppr-CKcr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ï†ÄÏû•Îêú Î™®Îç∏ Î°úÎìú\n",
    "model = TResNet(num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# Ï∂îÎ°†\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        # Í∞Å Î∞∞ÏπòÏùò ÌôïÎ•†ÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "        for prob in probs.cpu():  # prob: (num_classes,)\n",
    "            result = {\n",
    "                class_names[i]: prob[i].item()\n",
    "                for i in range(len(class_names))\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "pred = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKj-nq9RCKcr"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 379034,
     "status": "aborted",
     "timestamp": 1747893498647,
     "user": {
      "displayName": "Î∞ïÏßÑÏòÅ",
      "userId": "15299328254354703813"
     },
     "user_tz": -540
    },
    "id": "9VcLATLfCKcr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/car-classification/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' Ïª¨ÎüºÏùÑ Ï†úÏô∏Ìïú ÌÅ¥ÎûòÏä§ Ïª¨Îüº Ï†ïÎ†¨\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1053211,
     "sourceId": 1771962,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7483280,
     "sourceId": 11904337,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7492523,
     "sourceId": 11918208,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
